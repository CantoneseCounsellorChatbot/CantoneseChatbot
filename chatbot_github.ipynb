{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot_github.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python383jvsc74a57bd0f6b2f86bbbe13c4b3d4ec962c48b23699d251edd071ca6768a784c865f7bbfa8",
      "display_name": "Python 3.8.3 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CantoneseCounsellorChatbot/CantoneseChatbot/blob/main/chatbot_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4ewHjaWJoqJ",
        "outputId": "49771dae-2ea2-44df-aa47-7b7556879961"
      },
      "source": [
        "!rm -rf /content/CantoneseChatbot\n",
        "!pip install torch\n",
        "!pip install simpletransformers\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip install sqlite3\n",
        "!git clone https://github.com/CantoneseCounsellorChatbot/CantoneseChatbot.git\n",
        "# download question retrieval model\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1r5GRL51-DzoFrl3ba01HZqlPqmVu9cGv' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1r5GRL51-DzoFrl3ba01HZqlPqmVu9cGv\" -O pretrain-model.zip\n",
        "!rm -rf /tmp/cookies.txt\n",
        "! unzip -o -d CantoneseChatbot/ pretrain-model.zip"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: simpletransformers in /usr/local/lib/python3.7/dist-packages (0.61.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (2019.12.20)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.4.1)\n",
            "Requirement already satisfied: transformers>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (4.6.1)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (2.2)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (0.82.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.19.5)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.2.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.7.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (0.1.95)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (0.10.31)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (4.61.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->simpletransformers) (1.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.2.0->simpletransformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.2.0->simpletransformers) (0.0.45)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.2.0->simpletransformers) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=4.2.0->simpletransformers) (4.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.2.0->simpletransformers) (3.0.12)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardx->simpletransformers) (3.12.4)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (1.5.1)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (3.1.17)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (0.10.2)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (0.6.2)\n",
            "Requirement already satisfied: click<8.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (7.1.2)\n",
            "Requirement already satisfied: blinker in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (1.4)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (4.1.0)\n",
            "Requirement already satisfied: watchdog; platform_system != \"Darwin\" in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (2.1.2)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (0.18.2)\n",
            "Requirement already satisfied: base58 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (2.1.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (0.8.1)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (5.1.1)\n",
            "Requirement already satisfied: pyarrow; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (3.0.0)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (4.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (2.8.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->simpletransformers) (2018.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (2.10)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (2.0.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (0.70.11.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (0.3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (2021.5.0)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (3.5.4)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (1.15.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (0.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (3.13)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (2.3)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (5.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (1.1.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (1.0.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (5.4.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (0.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=4.2.0->simpletransformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=4.2.0->simpletransformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=4.2.0->simpletransformers) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardx->simpletransformers) (56.1.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython->streamlit->simpletransformers) (4.0.7)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (7.6.3)\n",
            "Requirement already satisfied: jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (2.11.3)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (5.0.5)\n",
            "Requirement already satisfied: ipykernel>=5.1.2; python_version >= \"3.4\" in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (5.5.5)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.11.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (2.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.3)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit->simpletransformers) (4.4.2)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython->streamlit->simpletransformers) (4.0.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.0.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.1.3)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (3.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10.1->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.0.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.3.5)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.8.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.3.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (22.0.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.10.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.6.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (3.3.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.4.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.5.1)\n",
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.17.84)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.61.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.84 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.20.84)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.4.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.84->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.84->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "fatal: destination path 'CantoneseChatbot' already exists and is not an empty directory.\n",
            "Archive:  pretrain-model.zip\n",
            "  inflating: CantoneseChatbot/pretrain-model/output_BTS_re+pr05190/model/config.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/output_BTS_re+pr05190/model/BertAbsSum_14.bin  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/eval_results.txt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/scheduler.pt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/special_tokens_map.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/vocab.txt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/tokenizer_config.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/model_args.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/training_args.bin  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/pytorch_model.bin  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/config.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/optimizer.pt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/eval_results.txt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/scheduler.pt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/special_tokens_map.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/vocab.txt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/tokenizer_config.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/model_args.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/training_args.bin  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/pytorch_model.bin  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/config.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/optimizer.pt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/eval_results.txt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/scheduler.pt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/special_tokens_map.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/vocab.txt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/tokenizer_config.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/model_args.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/training_args.bin  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/pytorch_model.bin  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/config.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/optimizer.pt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZqIpv_pKbPk"
      },
      "source": [
        "import sys\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "sys.path.append('/content/CantoneseChatbot/')\n",
        "from datetime import time\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from tqdm import tqdm\n",
        "from simpletransformers.classification import ClassificationModel\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "# import sqlite3\n",
        "import re\n",
        "# from models import *\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WT9qsh8bpR8"
      },
      "source": [
        "import sys\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# sys.path.append('/content/drive/My Drive/chatbot/BertSum')\n",
        "from datetime import time\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from tqdm import tqdm\n",
        "from simpletransformers.classification import ClassificationModel\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "# import sqlite3\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def regressionReply(post,model,candidate):\n",
        "  model = ClassificationModel(\"bert\", model )\n",
        "  data=pd.read_csv(candidate)\n",
        "  advice_list = data.advice.drop_duplicates().to_list()      \n",
        "  np.random.shuffle(advice_list)\n",
        "  tmp=[]\n",
        "  for advice in advice_list:\n",
        "      tmp.append([post,advice])\n",
        "\n",
        "\n",
        "  predictions, raw_outputs = model.predict(tmp)\n",
        "  topindex=np.argmax(predictions)\n",
        "  \n",
        "  \n",
        "  return tmp[topindex][1],max(predictions)\n",
        "\n",
        "'''\n",
        "def regressionReply(post,model,candidate):\n",
        "  # print(\"regression\")\n",
        "  tokenizer = BertTokenizer.from_pretrained(model)\n",
        "  model = BertForSequenceClassification.from_pretrained(model)\n",
        "  model.to('cuda')\n",
        "  data=pd.read_csv(candidate)\n",
        "  advice_list = data.advice.drop_duplicates().to_list()\n",
        "  text=post\n",
        "\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for a in advice_list:\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                      text+\"[SEP]\"+a,                      # Sentence to encode.\n",
        "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                      max_length = 50,           # Pad & truncate all sentences.\n",
        "                      pad_to_max_length = True,\n",
        "                      return_attention_mask = True,   # Construct attn. masks.\n",
        "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                  )\n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  batch_size = 32\n",
        "  # print(\"chatbot:{}\".format(advice))\n",
        "  prediction_data = TensorDataset(input_ids, attention_masks)\n",
        "  prediction_sampler = SequentialSampler(prediction_data)\n",
        "  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "  \n",
        "  predictions  = []\n",
        "  # print(\"regression2\")\n",
        "  # Predict \n",
        "  for batch in tqdm(prediction_dataloader):\n",
        "      batch = tuple(t.to(\"cuda\") for t in batch)\n",
        "      b_input_ids, b_input_mask = batch\n",
        "      with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy().reshape(-1).tolist()\n",
        "  #     label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Store predictions and true labels\n",
        "      predictions+=logits\n",
        "  #   true_labels.append(label_ids)\n",
        "\n",
        "  return advice_list[np.argmax(predictions)], np.max(predictions)\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "def general(aa):\n",
        "    max_tail_length=10\n",
        "    def getQAlist():\n",
        "        qaList = []\n",
        "        exact_list=[]\n",
        "        conn = pd.read_csv(\"/content/CantoneseChatbot/keyword_list.csv\")\n",
        "        exact_match = conn[conn.KeywordMatch==\"no\"]\n",
        "        conn=conn[conn.KeywordMatch==\"yes\"]\n",
        "        for index,row in exact_match.iterrows():\n",
        "            tmp = {\"Q\":\"\"+row[\"Q\"],\"A\":\"\"+row[\"A\"]}\n",
        "            exact_list.append(tmp)\n",
        "\n",
        "        \n",
        "        \n",
        "        for index,row in conn.iterrows():\n",
        "          if row[\"Q\"]!=\"*\":\n",
        "            tmp = {\"Q\":\"\"+row[\"Q\"],\"A\":\"\"+row[\"A\"]}\n",
        "            qaList.append(tmp)\n",
        "          else:\n",
        "            genreal_reply=row[\"A\"].split(\"|\")\n",
        "        return exact_list,qaList,genreal_reply\n",
        "\n",
        "    def answer(say,seg):\n",
        "        if (say[0]==\"你\") and (say.find(\"唔\")>0):\n",
        "            msg = handleSpecial(say,seg)\n",
        "            if msg !=\"\":\n",
        "                return msg\n",
        "        return \"@eliza@ \" + getAnswer(say)\n",
        "    def getAnswer(say):\n",
        "        exactmatch,tmpList,general_reply=getQAlist()\n",
        "        results = analyzeSay(say, tmpList, general_reply,exactmatch)\n",
        "        \n",
        "        msg=results[1]\n",
        "        if msg !=\"\":\n",
        "            return msg\n",
        "        else:\n",
        "            return \"然後呢？@发生错误@\"\n",
        "\n",
        "    def analyzeSay(say, tmpList, general_reply,exactmatch):\n",
        "        exact_df = pd.DataFrame(exactmatch)\n",
        "        if say in exact_df.Q.to_list():\n",
        "          return exact_df[exact_df.Q==say].A.item()\n",
        "        patterns = []\n",
        "        for i in range(len(tmpList)):\n",
        "            qa = tmpList[i]\n",
        "            qList = qa[\"Q\"].split(\" | \")\n",
        "            aList = qa[\"A\"].split(\"|\")            \n",
        "            elizakeyword = []\n",
        "            for j in range(len(qList)):\n",
        "                qi = qList[j]\n",
        " \n",
        "\n",
        "\n",
        "                if say.find(qi) >-1:\n",
        "\n",
        "\n",
        "                    elizakeyword.append(qi)\n",
        "                    tt=handlePunc(say, qi)\n",
        "\n",
        "                    tail = getTail(tt, qi)\n",
        "\n",
        "                    replacedTail = tail.replace(\"我\", \"#\")\n",
        "                    replacedTail = replacedTail.replace(\"你\", \"我\")\n",
        "                    replacedTail = replacedTail.replace(\"#\", \"你\")\n",
        "                    tmpalist =aList[np.random.randint(len(aList))]\n",
        "                    if tmpalist.find(\"*\")>-1:\n",
        "                      if len(replacedTail)<max_tail_length:\n",
        "                        msg = [tail, tmpalist.replace(\"*\", replacedTail)+\"$\"+qi+\"$\"]\n",
        "                        patterns.append(msg)\n",
        "                    else:\n",
        "                      msg = [tail, tmpalist.replace(\"*\", replacedTail)+\"$\"+qi+\"$\"]\n",
        "                      patterns.append(msg)\n",
        "\n",
        "        if patterns==[]:\n",
        "            patterns.append([say, general_reply[np.random.randint(len(general_reply))].replace(\"*\", say)+\"$\"+\"None\"+\"$\"])\n",
        "\n",
        "\n",
        "        return getRandomPattern(patterns)\n",
        "\n",
        "#             except:\n",
        "#                 print(i)\n",
        "\n",
        "\n",
        "    def getRandomPattern(patterns):\n",
        "        return patterns[np.random.randint(len(patterns))]\n",
        "#     def getTail(say, q):\n",
        "#         print(\"lbk\")\n",
        "#         r= re.compile(r\"(.*){}([^?.;]*)\".format(q))\n",
        "#         tmp = r.match(say)\n",
        "#         print(tmp)\n",
        "#         if tmp:\n",
        "#             return tmp[1]\n",
        "#         return \"\"\n",
        "    def getTail(say, q):\n",
        "        r= r\"(.*)({})([^?.;]*)\".format(q)\n",
        "        tmp = re.findall(r,say)\n",
        "        if tmp !=[] :\n",
        "            return tmp[0][2]\n",
        "        return \"\"\n",
        "\n",
        "    def handlePunc(say, keyword):\n",
        "        punct = [\",\", \"\\\\\\\\.\", \"!\", \"-\", \"\\\\\\\\?\", \"，\", \"！\", \"？\", \":\", \";\", \"；\", \"：\", \"。\", \"、\", \"…\"]\n",
        "        tmppunc=\"\".join(punct)\n",
        "        post = say.find(keyword)\n",
        "        if post == -1:\n",
        "            return say\n",
        "        r1=r\"[{}\\s](.*?{}.*?)[{}\\s]\".format(tmppunc,keyword,tmppunc)\n",
        "        r2=r\"[{}\\s]*(.*?{}.*?)[{}\\s]\".format(tmppunc,keyword,tmppunc)\n",
        "        r3=r\"[{}\\s](.*?{}.*?)[{}\\s]*\".format(tmppunc,keyword,tmppunc)\n",
        "        if re.findall(r1,say) !=[]:\n",
        "\n",
        "            return re.findall(r1,say)[0]\n",
        "        elif re.findall(r2,say) !=[]:\n",
        "\n",
        "            return re.findall(r2,say)[0]\n",
        "        elif re.findall(r3,say) !=[]:\n",
        "\n",
        "            return re.findall(r3,say)[0]\n",
        "        else:\n",
        "            return say\n",
        "    reply = answer(aa,aa)\n",
        "    return reply\n",
        "\n",
        "def chatbot(chatbot_params):\n",
        "  params_df=pd.DataFrame(chatbot_params).T\n",
        "  mode = params_df[params_df.index==\"mode\"].order.item()\n",
        "  params_df = params_df[params_df.index!=\"mode\"].sort_values(by=[\"order\"])\n",
        "  # print(params_df)\n",
        "  while True:\n",
        "    text=input(\"input:\")\n",
        "    label=0\n",
        "    plt.figure(dpi=20)\n",
        "    image = plt.imread('/content/CantoneseChatbot/flyingPig.jpg')\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    for index, row in params_df.iterrows():\n",
        "      if index == \"general\":\n",
        "          if mode ==\"debug\":\n",
        "              print(\"chatbot: {}\".format(general(text)))\n",
        "          else:\n",
        "              generaltext=general(text).split(\"$\")\n",
        "              print(\"chatbot: {}\".format(generaltext[0]))\n",
        "          break\n",
        "      elif index==\"advice\":\n",
        "        modelpath = \"/content/CantoneseChatbot/pretrain-model/regression_advice/bestmodel\"\n",
        "        advicepath= \"/content/CantoneseChatbot/candidate/adviceall.csv\"\n",
        "        reply, score = regressionReply(text,modelpath,advicepath)\n",
        "        if mode ==\"debug\":\n",
        "            print(\"chatbot: {}\\nscore:{}\".format(reply,score))\n",
        "            if score > row[\"Threshold\"]:\n",
        "              break\n",
        "            else:\n",
        "              continue\n",
        "        elif score > row[\"Threshold\"]:\n",
        "            print(\"chatbot: {}\".format(reply))\n",
        "            break\n",
        "      elif index==\"question\":\n",
        "        modelpath = \"/content/CantoneseChatbot/pretrain-model/regression_question/bestmodel\"\n",
        "        advicepath= \"/content/CantoneseChatbot/candidate/question.csv\"\n",
        "        reply, score = regressionReply(text,modelpath,advicepath)\n",
        "        if mode ==\"debug\":\n",
        "            print(\"chatbot: {}\\nscore:{}\".format(reply,score))\n",
        "            if score > row[\"Threshold\"]:\n",
        "              break\n",
        "            else:\n",
        "              continue\n",
        "        elif score > row[\"Threshold\"]:\n",
        "            print(\"chatbot: {}\".format(reply))\n",
        "            break\n",
        "      elif index==\"restatement\":\n",
        "        modelpath = \"/content/CantoneseChatbot/pretrain-model/regression_restatement/bestmodel\"\n",
        "        advicepath= \"/content/CantoneseChatbot/candidate/restatement.csv\"\n",
        "        reply, score = regressionReply(text,modelpath,advicepath)\n",
        "        if mode ==\"debug\":\n",
        "            print(\"chatbot: {}\\nscore:{}\".format(reply,score))\n",
        "            if score > row[\"Threshold\"]:\n",
        "              break\n",
        "            else:\n",
        "              continue\n",
        "        elif score > row[\"Threshold\"]:\n",
        "            print(\"chatbot: {}\".format(reply))\n",
        "            break\n",
        "      elif index==\"bertsum\":\n",
        "        print(\"chatbot: {}\".format(general(text,10)))\n",
        "        break\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCdJCiYVkago"
      },
      "source": [
        "# The default response order is advice-->question-->restatement-->bertsum, you can change the order by changing the parameter b\n",
        "# The threshold of \"advice\",\"question\"and\"restatement\" ranges from 0 to 1.1\n",
        "# The threshold of \"bertsum\" ranges from -10 to 0\n",
        "chatbot_params={\"advice\":{\"Threshold\":1.0,\"order\":2},\n",
        "                \"question\":{\"Threshold\":1.0,\"order\":5},\n",
        "                \"restatement\":{\"Threshold\":1.0,\"order\":1},\n",
        "                \"bertsum\":{\"Threshold\":-2,\"order\":4},\n",
        "                \"general\":{\"Threshold\":1.0,\"order\":0},\n",
        "                \"mode\":\"debug\"\n",
        "                }"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "lOrZoU53JkEs",
        "outputId": "cd3a21ba-d6c9-4890-ba2e-0ddc794fe7fb"
      },
      "source": [
        "chatbot(chatbot_params)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input:我覺得辛苦\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 120x80 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "chatbot: @eliza@ 點解有咁既感覺?$覺得$\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m         \u001b[0;31m# flush i/o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-b575470cc62c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchatbot_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-73-0aab285af2b2>\u001b[0m in \u001b[0;36mchatbot\u001b[0;34m(chatbot_params)\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;31m# print(params_df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m                                       reply_content, parent, ident)\n\u001b[1;32m    703\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_is_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \"\"\"Override in subclasses to find completions.\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m         self.session.send(stream, 'apply_reply', reply_content,\n\u001b[1;32m    736\u001b[0m                     parent=parent, ident=ident,buffers=result_buf, metadata=md)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH9oTgkeHGiN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDN5UUUIHEZ1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYZ2TNpzxclL"
      },
      "source": [
        "# BertSum, still have some bug\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "from tqdm import tqdm, trange\n",
        "import json\n",
        "\n",
        "from preprocess import LCSTSProcessor, convert_examples_to_features, create_dataset\n",
        "from model import BertAbsSum\n",
        "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
        "from utils import rouge\n",
        "from utils import convert_to_unicode\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, src, tgt=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            src: string. The untokenized text of the target sequence.\n",
        "            tgt: (Optional) string. The untokenized text of the target.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
        "                    level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--model_path\",\n",
        "                    default=None,\n",
        "                    type=str,\n",
        "                    required=True,\n",
        "                    help=\"The path to trained model.\")\n",
        "parser.add_argument(\"--config_path\",\n",
        "                    default=None,\n",
        "                    type=str,\n",
        "                    required=True,\n",
        "                    help=\"The path to config file.\")                    \n",
        "# parser.add_argument(\"--eval_path\",\n",
        "#                     default=None,\n",
        "#                     type=str,\n",
        "#                     required=True,\n",
        "#                     help=\"The path to the evaluation data. Should end with .tsv.\")\n",
        "parser.add_argument(\"--bert_model\", \n",
        "                    default=None, \n",
        "                    type=str, \n",
        "                    required=True,\n",
        "                    help=\"Bert pre-trained model selected in the list: bert-base-uncased, \"\n",
        "                    \"bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, \"\n",
        "                    \"bert-base-multilingual-cased, bert-base-chinese.\")\n",
        "# parser.add_argument(\"--result_path\",\n",
        "#                     default=None,\n",
        "#                     type=str,\n",
        "#                     required=True,\n",
        "#                     help=\"The path where you save your results.\")                    \n",
        "parser.add_argument(\"--max_src_len\",\n",
        "                    default=130,\n",
        "                    type=int,\n",
        "                    help=\"Max sequence length for source text. Sequences will be truncated or padded to this length\")\n",
        "parser.add_argument(\"--max_tgt_len\",\n",
        "                    default=30,\n",
        "                    type=int,\n",
        "                    help=\"Max sequence length for target text. Sequences will be truncated or padded to this length\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # args = parser.parse_args()\n",
        "    args = parser.parse_args(args=['--model_path','/content/drive/MyDrive/chatbot/pretrain-model/output_BTS_re+pr05190/model/BertAbsSum_14.bin',\n",
        "                                   '--config_path','/content/drive/MyDrive/chatbot/pretrain-model/output_BTS_re+pr05190/model/config.json',\n",
        "                                   '--bert_model','/content/drive/MyDrive/chatbot/BertSum/pretrained_model/bert-base-chinese'])\n",
        "\n",
        "\n",
        "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device=torch.device(\"cpu\")\n",
        "    with open(args.config_path, 'r') as f:\n",
        "        config = json.load(f)\n",
        "    model = BertAbsSum(args.bert_model, config['decoder_config'], device)\n",
        "    model.load_state_dict(torch.load(args.model_path))\n",
        "    model.to(device)\n",
        "\n",
        "    processor = LCSTSProcessor()\n",
        "    tokenizer = BertTokenizer.from_pretrained(os.path.join(args.bert_model, 'vocab.txt'))\n",
        "    # test_examples = processor.get_examples(args.eval_path)\n",
        "    post=input(\"input:\")\n",
        "    test_examples = [InputExample(guid=0,src=convert_to_unicode(post),tgt=convert_to_unicode(post)),InputExample(guid=1,src=convert_to_unicode(post),tgt=convert_to_unicode(post))]\n",
        "    test_features = convert_examples_to_features(test_examples, args.max_src_len, args.max_tgt_len, tokenizer)\n",
        "    test_data = create_dataset(test_features)\n",
        "\n",
        "    test_sampler = SequentialSampler(test_data)\n",
        "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE, drop_last=True)\n",
        "\n",
        "    model.eval()\n",
        "    # if not os.path.exists(args.result_path):\n",
        "    #     os.mkdir(args.result_path)\n",
        "    # f_log = open(os.path.join(args.result_path, 'log.txt'), 'w', encoding='utf-8')\n",
        "\n",
        "    hyp_list = []\n",
        "    ref_list = []\n",
        "    for batch in tqdm(test_dataloader, desc=\"Iteration\"):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        pred, beam_score = model.beam_decode(batch[0], batch[1], 3, 3)\n",
        "        src, tgt = batch[0], batch[2]\n",
        "        for i in range(BATCH_SIZE):\n",
        "            sample_src = \"\".join(tokenizer.convert_ids_to_tokens(src[i].cpu().numpy())).split('[CLS]')[1].split('[SEP]')[0] + '\\n'\n",
        "            sample_tgt = \"\".join(tokenizer.convert_ids_to_tokens(tgt[i].cpu().numpy())).split('[CLS]')[1].split('[SEP]')[0] + '\\n'\n",
        "            sample_pred = \"\".join(tokenizer.convert_ids_to_tokens(pred[i][0])).split('[SEP]')[0] + '\\n'\n",
        "            sample_pred_2 = \"\".join(tokenizer.convert_ids_to_tokens(pred[i][1])).split('[SEP]')[0] + '\\n'\n",
        "            sample_pred_3 = \"\".join(tokenizer.convert_ids_to_tokens(pred[i][2])).split('[SEP]')[0] + '\\n'\n",
        "\n",
        "            print('Hypothesis: ' + sample_pred)\n",
        "\n",
        "\n",
        "\n",
        "            print('score: ' + str(beam_score[i]))\n",
        "            \n",
        "            # f_hyp.write(sample_pred)\n",
        "            # f_ref.write(sample_tgt)\n",
        "\n",
        "\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71XcRXC1NQ_e"
      },
      "source": [
        "!rm -rf /content/CantoneseChatbot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao7AR8SLPBe3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}