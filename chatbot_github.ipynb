{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot_github.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python383jvsc74a57bd0f6b2f86bbbe13c4b3d4ec962c48b23699d251edd071ca6768a784c865f7bbfa8",
      "display_name": "Python 3.8.3 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CantoneseCounsellorChatbot/CantoneseChatbot/blob/main/chatbot_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b4ewHjaWJoqJ",
        "outputId": "7535ec6e-b264-4724-d412-196e84275b4d"
      },
      "source": [
        "!pip install torch\n",
        "!pip install simpletransformers\n",
        "!pip install pytorch_pretrained_bert\n",
        "# !pip install sqlite3\n",
        "!git clone https://github.com/CantoneseCounsellorChatbot/CantoneseChatbot.git\n",
        "# download question retrieval model\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1r5GRL51-DzoFrl3ba01HZqlPqmVu9cGv' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1r5GRL51-DzoFrl3ba01HZqlPqmVu9cGv\" -O pretrain-model.zip\n",
        "!rm -rf /tmp/cookies.txt\n",
        "! unzip -o -d CantoneseChatbot/ pretrain-model.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Collecting simpletransformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/2b/9073313586a8cdd7997b2f4ed43c0a44d9c484013b51f77c1c0f034dd78b/simpletransformers-0.61.6-py3-none-any.whl (220kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 8.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (0.22.2.post1)\n",
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/48/b199e2b3b341ac842108c5db4956091dd75d961cfa77aceb033e99cac20f/wandb-0.10.31-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.1.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.19.5)\n",
            "Collecting tokenizers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 49.8MB/s \n",
            "\u001b[?25hCollecting transformers>=4.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (2.23.0)\n",
            "Collecting streamlit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/11/57097e14f72a2d1b2a1bbe86c2a8bc375661bfd5c30b5e8cee7c2fad9a44/streamlit-0.82.0-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 39.8MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hCollecting tqdm>=4.47.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/d7/f357d98e9b50346bcb6095fe3ad205d8db3174eb5edb03edfe7c4099576d/tqdm-4.61.0-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.2MB/s \n",
            "\u001b[?25hCollecting tensorboardx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 58.0MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/f8/ff7cd6e3b400b33dcbbfd31c6c1481678a2b2f669f521ad20053009a9aa3/datasets-1.7.0-py3-none-any.whl (234kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from simpletransformers) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->simpletransformers) (1.0.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (3.13)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (3.12.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (2.8.1)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/da/6f6224fdfc47dab57881fe20c0d1bc3122be290198ba0bf26a953a045d92/GitPython-3.1.17-py3-none-any.whl (166kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 51.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (7.1.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.7MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (1.15.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (5.4.8)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/4a/a54b254f67d8f4052338d54ebe90126f200693440a93ef76d254d581e3ec/sentry_sdk-1.1.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->simpletransformers) (2.3)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->simpletransformers) (2018.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.2.0->simpletransformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.2.0->simpletransformers) (20.9)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 33.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=4.2.0->simpletransformers) (4.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers) (3.0.4)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (0.10.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (0.8.1)\n",
            "Collecting base58\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/a1/d9f565e9910c09fd325dc638765e8843a19fa696275c16cc08cf3b0a3c25/base58-2.1.0-py3-none-any.whl\n",
            "Collecting pydeck>=0.1.dev5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/bc/f0e44828e4290367c869591d50d3671a4d0ee94926da6cb734b7b200308c/pydeck-0.6.2-py2.py3-none-any.whl (4.2MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2MB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (1.5.1)\n",
            "Requirement already satisfied: pyarrow; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (3.0.0)\n",
            "Collecting watchdog; platform_system != \"Darwin\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/5b/36b3b11e557830de6fc1dc06e9aa3ee274119b8cea9cc98175dbbf72cf87/watchdog-2.1.2-py3-none-manylinux2014_x86_64.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (4.2.2)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (4.1.0)\n",
            "Collecting blinker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 55.4MB/s \n",
            "\u001b[?25hCollecting validators\n",
            "  Downloading https://files.pythonhosted.org/packages/db/2f/7fed3ee94ad665ad2c1de87f858f10a7785251ff75b4fd47987888d07ef1/validators-0.18.2-py3-none-any.whl\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (7.1.2)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers) (5.1.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (0.70.11.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers) (0.3.3)\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/52/816d1a3a599176057bf29dfacb1f8fadb61d35fbd96cb1bab4aaa7df83c0/fsspec-2021.5.0-py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 49.4MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 55.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb->simpletransformers) (56.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb->simpletransformers) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=4.2.0->simpletransformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=4.2.0->simpletransformers) (3.4.1)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (5.0.5)\n",
            "Requirement already satisfied: jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (2.11.3)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (7.6.3)\n",
            "Collecting ipykernel>=5.1.2; python_version >= \"3.4\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/6d/6c8fe4b658f77947d4244ce81f60230c4c8d1dc1a21ae83e63b269339178/ipykernel-5.5.5-py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 56.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (2.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.11.1)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit->simpletransformers) (4.4.2)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10.1->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.0.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.1.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (3.5.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.3.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.0.18)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.7.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.3.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (22.0.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.5)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.10.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.4.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (3.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.5.1)\n",
            "Building wheels for collected packages: seqeval, subprocess32, pathtools, blinker\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=b6e9b51f7ff1f7681cf6feca96d14d322196688d06b199796fd364a28d51bfd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=9af89ed434a353f02700a1385d7ec3b6aca05232132bb35d472b74f5f13644b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=4794ededff1d0d1a4c15ffc583a2f5f560436ac6e1349a6ab8ff3db00ce7ac34\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-cp37-none-any.whl size=13448 sha256=62a12ac7bb21c6f6797a4c761a98751bd0ba4afd9fec79e0f3ce7b163addb511\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n",
            "Successfully built seqeval subprocess32 pathtools blinker\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.5.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datasets 1.7.0 has requirement tqdm<4.50.0,>=4.27, but you'll have tqdm 4.61.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sentencepiece, smmap, gitdb, GitPython, docker-pycreds, subprocess32, shortuuid, pathtools, sentry-sdk, configparser, wandb, tokenizers, tqdm, huggingface-hub, sacremoses, transformers, base58, ipykernel, pydeck, watchdog, blinker, validators, streamlit, seqeval, tensorboardx, fsspec, xxhash, datasets, simpletransformers\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "Successfully installed GitPython-3.1.17 base58-2.1.0 blinker-1.4 configparser-5.0.2 datasets-1.7.0 docker-pycreds-0.4.0 fsspec-2021.5.0 gitdb-4.0.7 huggingface-hub-0.0.8 ipykernel-5.5.5 pathtools-0.1.2 pydeck-0.6.2 sacremoses-0.0.45 sentencepiece-0.1.95 sentry-sdk-1.1.0 seqeval-1.2.2 shortuuid-1.0.1 simpletransformers-0.61.6 smmap-4.0.0 streamlit-0.82.0 subprocess32-3.5.4 tensorboardx-2.2 tokenizers-0.10.3 tqdm-4.61.0 transformers-4.6.1 validators-0.18.2 wandb-0.10.31 watchdog-2.1.2 xxhash-2.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 19.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 10.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.61.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/20/4294e37c3c6936c905f1e9da958c776d7fee54a4512bdb7706d69c8720e6/boto3-1.17.84-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 11.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Collecting botocore<1.21.0,>=1.20.84\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/22/72c81d754bbcb128cba2ad88670c3c320e4594e6ddd8cca6512c3967108c/botocore-1.20.84-py2.py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 10.6MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.84->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.84->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.20.84 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.17.84 botocore-1.20.84 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GHgzgJ7dglG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19ebac85-1dfe-49d6-dc39-25fb9d294c77"
      },
      "source": [
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  pretrain-model.zip\n",
            "   creating: CantoneseChatbot/pretrain-model/\n",
            "   creating: CantoneseChatbot/pretrain-model/output_BTS_re+pr05190/\n",
            "   creating: CantoneseChatbot/pretrain-model/output_BTS_re+pr05190/model/\n",
            "  inflating: CantoneseChatbot/pretrain-model/output_BTS_re+pr05190/model/config.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/output_BTS_re+pr05190/model/BertAbsSum_14.bin  \n",
            "   creating: CantoneseChatbot/pretrain-model/regression_question/\n",
            "   creating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/\n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/eval_results.txt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/scheduler.pt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/special_tokens_map.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/vocab.txt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/tokenizer_config.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/model_args.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/training_args.bin  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/pytorch_model.bin  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/config.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_question/bestmodel/optimizer.pt  \n",
            "   creating: CantoneseChatbot/pretrain-model/regression_restatement/\n",
            "   creating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/\n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/eval_results.txt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/scheduler.pt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/special_tokens_map.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/vocab.txt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/tokenizer_config.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/model_args.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/training_args.bin  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/pytorch_model.bin  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/config.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_restatement/bestmodel/optimizer.pt  \n",
            "   creating: CantoneseChatbot/pretrain-model/regression_advice/\n",
            "   creating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/\n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/eval_results.txt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/scheduler.pt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/special_tokens_map.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/vocab.txt  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/tokenizer_config.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/model_args.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/training_args.bin  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/pytorch_model.bin  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/config.json  \n",
            "  inflating: CantoneseChatbot/pretrain-model/regression_advice/bestmodel/optimizer.pt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZqIpv_pKbPk"
      },
      "source": [
        "import sys\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# sys.path.append('/content/drive/My Drive/chatbot/BertSum')\n",
        "from datetime import time\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "# import sqlite3\n",
        "import re\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0PRuSqkW9Jw"
      },
      "source": [
        "def regressionReply(post,model,candidate):\n",
        "  # print(\"regression\")\n",
        "  tokenizer = BertTokenizer.from_pretrained(model)\n",
        "  model = BertForSequenceClassification.from_pretrained(model)\n",
        "  model.to('cuda')\n",
        "  data=pd.read_csv(candidate)\n",
        "  advice_list = data.advice.drop_duplicates().to_list()\n",
        "  text=post\n",
        "\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for a in advice_list:\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                      text+\"[SEP]\"+a,                      # Sentence to encode.\n",
        "                      add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                      max_length = 50,           # Pad & truncate all sentences.\n",
        "                      pad_to_max_length = True,\n",
        "                      return_attention_mask = True,   # Construct attn. masks.\n",
        "                      return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                  )\n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  batch_size = 32\n",
        "  # print(\"chatbot:{}\".format(advice))\n",
        "  prediction_data = TensorDataset(input_ids, attention_masks)\n",
        "  prediction_sampler = SequentialSampler(prediction_data)\n",
        "  prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "  \n",
        "  predictions  = []\n",
        "  # print(\"regression2\")\n",
        "  # Predict \n",
        "  for batch in tqdm(prediction_dataloader):\n",
        "      batch = tuple(t.to(\"cuda\") for t in batch)\n",
        "      b_input_ids, b_input_mask = batch\n",
        "      with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy().reshape(-1).tolist()\n",
        "  #     label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Store predictions and true labels\n",
        "      predictions+=logits\n",
        "  #   true_labels.append(label_ids)\n",
        "\n",
        "  return advice_list[np.argmax(predictions)], np.max(predictions)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ9O-QMYEpev"
      },
      "source": [
        "def general(aa):\n",
        "    def getQAlist():\n",
        "        qaList = []\n",
        "        conn = pd.read_csv(\"/content/CantoneseChatbot/keyword_list.csv\")\n",
        "        \n",
        "\n",
        "        for index,row in conn.iterrows():\n",
        "          if pd.notna(row[\"Q\"]):\n",
        "            tmp = {\"Q\":\"\"+row[\"Q\"],\"A\":\"\"+row[\"A\"]}\n",
        "            qaList.append(tmp)\n",
        "          else:\n",
        "            genreal_reply=row[\"A\"].split(\"|\")\n",
        "        return qaList,genreal_reply\n",
        "\n",
        "    def answer(say,seg):\n",
        "        if (say[0]==\"你\") and (say.find(\"唔\")>0):\n",
        "            msg = handleSpecial(say,seg)\n",
        "            if msg !=\"\":\n",
        "                return msg\n",
        "        return \"@eliza@ \" + getAnswer(say)\n",
        "    def getAnswer(say):\n",
        "        tmpList,general_reply=getQAlist()\n",
        "        results = analyzeSay(say, tmpList, general_reply)\n",
        "        \n",
        "        msg=results[1]\n",
        "        if msg !=\"\":\n",
        "            return msg\n",
        "        else:\n",
        "            return \"然後呢？@发生错误@\"\n",
        "\n",
        "    def analyzeSay(say, tmpList, general_reply):\n",
        "        patterns = []\n",
        "        for i in range(len(tmpList)):\n",
        "            qa = tmpList[i]\n",
        "            qList = qa[\"Q\"].split(\" | \")\n",
        "            aList = qa[\"A\"].split(\"|\")            \n",
        "            elizakeyword = []\n",
        "            for j in range(len(qList)):\n",
        "                qi = qList[j]\n",
        " \n",
        "\n",
        "\n",
        "                if say.find(qi) >-1:\n",
        "\n",
        "\n",
        "                    elizakeyword.append(qi)\n",
        "                    tt=handlePunc(say, qi)\n",
        "\n",
        "                    tail = getTail(tt, qi)\n",
        "\n",
        "                    replacedTail = tail.replace(\"我\", \"#\")\n",
        "                    replacedTail = replacedTail.replace(\"你\", \"我\")\n",
        "                    replacedTail = replacedTail.replace(\"#\", \"你\")\n",
        "                    msg = [tail, aList[np.random.randint(len(aList))].replace(\"*\", replacedTail)+\"$\"+qi+\"$\"]\n",
        "                    patterns.append(msg)\n",
        "        if patterns==[]:\n",
        "            patterns.append([say, general_reply[np.random.randint(len(general_reply))].replace(\"*\", say)+\"$\"+\"None\"+\"$\"])\n",
        "\n",
        "\n",
        "        return getRandomPattern(patterns)\n",
        "\n",
        "#             except:\n",
        "#                 print(i)\n",
        "\n",
        "\n",
        "    def getRandomPattern(patterns):\n",
        "        return patterns[np.random.randint(len(patterns))]\n",
        "#     def getTail(say, q):\n",
        "#         print(\"lbk\")\n",
        "#         r= re.compile(r\"(.*){}([^?.;]*)\".format(q))\n",
        "#         tmp = r.match(say)\n",
        "#         print(tmp)\n",
        "#         if tmp:\n",
        "#             return tmp[1]\n",
        "#         return \"\"\n",
        "    def getTail(say, q):\n",
        "        r= r\"(.*)({})([^?.;]*)\".format(q)\n",
        "        tmp = re.findall(r,say)\n",
        "        if tmp !=[] :\n",
        "            return tmp[0][2]\n",
        "        return \"\"\n",
        "\n",
        "    def handlePunc(say, keyword):\n",
        "        punct = [\",\", \"\\\\\\\\.\", \"!\", \"-\", \"\\\\\\\\?\", \"，\", \"！\", \"？\", \":\", \";\", \"；\", \"：\", \"。\", \"、\", \"…\"]\n",
        "        tmppunc=\"\".join(punct)\n",
        "        post = say.find(keyword)\n",
        "        if post == -1:\n",
        "            return say\n",
        "        r1=r\"[{}\\s](.*?{}.*?)[{}\\s]\".format(tmppunc,keyword,tmppunc)\n",
        "        r2=r\"[{}\\s]*(.*?{}.*?)[{}\\s]\".format(tmppunc,keyword,tmppunc)\n",
        "        r3=r\"[{}\\s](.*?{}.*?)[{}\\s]*\".format(tmppunc,keyword,tmppunc)\n",
        "        if re.findall(r1,say) !=[]:\n",
        "\n",
        "            return re.findall(r1,say)[0]\n",
        "        elif re.findall(r2,say) !=[]:\n",
        "\n",
        "            return re.findall(r2,say)[0]\n",
        "        elif re.findall(r3,say) !=[]:\n",
        "\n",
        "            return re.findall(r3,say)[0]\n",
        "        else:\n",
        "            return say\n",
        "    reply = answer(aa,aa)\n",
        "    return reply"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpfEGlzYzlyP"
      },
      "source": [
        "def chatbot(chatbot_params):\n",
        "  params_df=pd.DataFrame(chatbot_params).T.sort_values(by=[\"order\"])\n",
        "  while True:\n",
        "    text=input(\"input:\")\n",
        "    label=0\n",
        "    for index, row in params_df.iterrows():\n",
        "      if index == \"general\":\n",
        "        print(\"chatbot: {}\".format(general(text)))\n",
        "        break\n",
        "      elif index==\"advice\":\n",
        "        modelpath = \"/content/CantoneseChatbot/pretrain-model/regression_advice/bestmodel\"\n",
        "        advicepath= \"/content/CantoneseChatbot/candidate/adviceall.csv\"\n",
        "        reply, score = regressionReply(text,modelpath,advicepath)\n",
        "        if score > row[\"Threshold\"]:\n",
        "          print(\"chatbot: {}\".format(reply))\n",
        "          break\n",
        "        continue\n",
        "      elif index==\"question\":\n",
        "        modelpath = \"/content/CantoneseChatbot/pretrain-model/regression_question/bestmodel\"\n",
        "        advicepath= \"/content/CantoneseChatbot/candidate/question.csv\"\n",
        "        reply, score = regressionReply(text,modelpath,advicepath)\n",
        "        if score > row[\"Threshold\"]:\n",
        "          print(\"chatbot: {}\".format(reply))\n",
        "          break\n",
        "        continue\n",
        "      elif index==\"restatement\":\n",
        "        modelpath = \"/content/CantoneseChatbot/pretrain-model/regression_restatement/bestmodel\"\n",
        "        advicepath= \"/content/CantoneseChatbot/candidate/restatement.csv\"\n",
        "        reply, score = regressionReply(text,modelpath,advicepath)\n",
        "        if score > row[\"Threshold\"]:\n",
        "          print(\"chatbot: {}\".format(reply))\n",
        "          break\n",
        "        continue\n",
        "      elif index==\"bertsum\":\n",
        "        print(\"chatbot: {}\".format(general(text)))\n",
        "        break\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCdJCiYVkago"
      },
      "source": [
        "# The default response order is advice-->question-->restatement-->bertsum, you can change the order by changing the parameter b\n",
        "# The threshold of \"advice\",\"question\"and\"restatement\" ranges from 0 to 1.1\n",
        "# The threshold of \"bertsum\" ranges from -10 to 0\n",
        "chatbot_params={\"advice\":{\"Threshold\":1.0,\"order\":1},\n",
        "                \"question\":{\"Threshold\":1.0,\"order\":2},\n",
        "                \"restatement\":{\"Threshold\":1.0,\"order\":3},\n",
        "                \"bertsum\":{\"Threshold\":-2,\"order\":4},\n",
        "                \"general\":{\"Threshold\":None,\"order\":5}\n",
        "                }"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "lOrZoU53JkEs",
        "outputId": "4a950afa-bf4f-430e-e08a-c6d7d08d2b44"
      },
      "source": [
        "chatbot(chatbot_params)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input:hello\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "  0%|          | 0/143 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "regression2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 143/143 [00:11<00:00, 12.05it/s]\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "  1%|          | 1/139 [00:00<00:17,  7.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "regression2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 139/139 [00:11<00:00, 11.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "chatbot: 你係咪有好明確嘅目標？\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m         \u001b[0;31m# flush i/o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b575470cc62c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchatbot_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-f8f997c0eb15>\u001b[0m in \u001b[0;36mchatbot\u001b[0;34m(chatbot_params)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mparams_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchatbot_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"order\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m                                       reply_content, parent, ident)\n\u001b[1;32m    703\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_is_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \"\"\"Override in subclasses to find completions.\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m         self.session.send(stream, 'apply_reply', reply_content,\n\u001b[1;32m    736\u001b[0m                     parent=parent, ident=ident,buffers=result_buf, metadata=md)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wYZ2TNpzxclL",
        "outputId": "753fe7ba-8a5b-41bc-e2bc-57fc28b4a9b4"
      },
      "source": [
        "# BertSum, still have some bug\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "from tqdm import tqdm, trange\n",
        "import json\n",
        "\n",
        "from preprocess import LCSTSProcessor, convert_examples_to_features, create_dataset\n",
        "from model import BertAbsSum\n",
        "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
        "from utils import rouge\n",
        "from utils import convert_to_unicode\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, src, tgt=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            src: string. The untokenized text of the target sequence.\n",
        "            tgt: (Optional) string. The untokenized text of the target.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
        "                    level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--model_path\",\n",
        "                    default=None,\n",
        "                    type=str,\n",
        "                    required=True,\n",
        "                    help=\"The path to trained model.\")\n",
        "parser.add_argument(\"--config_path\",\n",
        "                    default=None,\n",
        "                    type=str,\n",
        "                    required=True,\n",
        "                    help=\"The path to config file.\")                    \n",
        "# parser.add_argument(\"--eval_path\",\n",
        "#                     default=None,\n",
        "#                     type=str,\n",
        "#                     required=True,\n",
        "#                     help=\"The path to the evaluation data. Should end with .tsv.\")\n",
        "parser.add_argument(\"--bert_model\", \n",
        "                    default=None, \n",
        "                    type=str, \n",
        "                    required=True,\n",
        "                    help=\"Bert pre-trained model selected in the list: bert-base-uncased, \"\n",
        "                    \"bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, \"\n",
        "                    \"bert-base-multilingual-cased, bert-base-chinese.\")\n",
        "# parser.add_argument(\"--result_path\",\n",
        "#                     default=None,\n",
        "#                     type=str,\n",
        "#                     required=True,\n",
        "#                     help=\"The path where you save your results.\")                    \n",
        "parser.add_argument(\"--max_src_len\",\n",
        "                    default=130,\n",
        "                    type=int,\n",
        "                    help=\"Max sequence length for source text. Sequences will be truncated or padded to this length\")\n",
        "parser.add_argument(\"--max_tgt_len\",\n",
        "                    default=30,\n",
        "                    type=int,\n",
        "                    help=\"Max sequence length for target text. Sequences will be truncated or padded to this length\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # args = parser.parse_args()\n",
        "    args = parser.parse_args(args=['--model_path','/content/drive/MyDrive/chatbot/pretrain-model/output_BTS_re+pr05190/model/BertAbsSum_14.bin',\n",
        "                                   '--config_path','/content/drive/MyDrive/chatbot/pretrain-model/output_BTS_re+pr05190/model/config.json',\n",
        "                                   '--bert_model','/content/drive/MyDrive/chatbot/BertSum/pretrained_model/bert-base-chinese'])\n",
        "\n",
        "\n",
        "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device=torch.device(\"cpu\")\n",
        "    with open(args.config_path, 'r') as f:\n",
        "        config = json.load(f)\n",
        "    model = BertAbsSum(args.bert_model, config['decoder_config'], device)\n",
        "    model.load_state_dict(torch.load(args.model_path))\n",
        "    model.to(device)\n",
        "\n",
        "    processor = LCSTSProcessor()\n",
        "    tokenizer = BertTokenizer.from_pretrained(os.path.join(args.bert_model, 'vocab.txt'))\n",
        "    # test_examples = processor.get_examples(args.eval_path)\n",
        "    post=input(\"input:\")\n",
        "    test_examples = [InputExample(guid=0,src=convert_to_unicode(post),tgt=convert_to_unicode(post)),InputExample(guid=1,src=convert_to_unicode(post),tgt=convert_to_unicode(post))]\n",
        "    test_features = convert_examples_to_features(test_examples, args.max_src_len, args.max_tgt_len, tokenizer)\n",
        "    test_data = create_dataset(test_features)\n",
        "\n",
        "    test_sampler = SequentialSampler(test_data)\n",
        "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE, drop_last=True)\n",
        "\n",
        "    model.eval()\n",
        "    # if not os.path.exists(args.result_path):\n",
        "    #     os.mkdir(args.result_path)\n",
        "    # f_log = open(os.path.join(args.result_path, 'log.txt'), 'w', encoding='utf-8')\n",
        "\n",
        "    hyp_list = []\n",
        "    ref_list = []\n",
        "    for batch in tqdm(test_dataloader, desc=\"Iteration\"):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        pred, beam_score = model.beam_decode(batch[0], batch[1], 3, 3)\n",
        "        src, tgt = batch[0], batch[2]\n",
        "        for i in range(BATCH_SIZE):\n",
        "            sample_src = \"\".join(tokenizer.convert_ids_to_tokens(src[i].cpu().numpy())).split('[CLS]')[1].split('[SEP]')[0] + '\\n'\n",
        "            sample_tgt = \"\".join(tokenizer.convert_ids_to_tokens(tgt[i].cpu().numpy())).split('[CLS]')[1].split('[SEP]')[0] + '\\n'\n",
        "            sample_pred = \"\".join(tokenizer.convert_ids_to_tokens(pred[i][0])).split('[SEP]')[0] + '\\n'\n",
        "            sample_pred_2 = \"\".join(tokenizer.convert_ids_to_tokens(pred[i][1])).split('[SEP]')[0] + '\\n'\n",
        "            sample_pred_3 = \"\".join(tokenizer.convert_ids_to_tokens(pred[i][2])).split('[SEP]')[0] + '\\n'\n",
        "\n",
        "            print('Hypothesis: ' + sample_pred)\n",
        "\n",
        "\n",
        "\n",
        "            print('score: ' + str(beam_score[i]))\n",
        "            \n",
        "            # f_hyp.write(sample_pred)\n",
        "            # f_ref.write(sample_tgt)\n",
        "\n",
        "\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/25/2021 15:35:04 - INFO - pytorch_pretrained_bert.modeling -   loading archive file /content/drive/MyDrive/chatbot/BertSum/pretrained_model/bert-base-chinese\n",
            "05/25/2021 15:35:04 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "05/25/2021 15:35:11 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file /content/drive/MyDrive/chatbot/BertSum/pretrained_model/bert-base-chinese/vocab.txt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "input:hello\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "examples: 100%|██████████| 2/2 [00:00<00:00, 5611.11it/s]\n",
            "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "lbk\n",
            "[tensor([0.0775, 0.0794, 0.3002])]\n",
            "tensor(0.0775)\n",
            "lbk\n",
            "[tensor([0.0775, 0.0794, 0.3002])]\n",
            "tensor(0.0794)\n",
            "lbk\n",
            "[tensor([0.0775, 0.0794, 0.3002])]\n",
            "tensor(0.3002)\n",
            "lbk\n",
            "[tensor([0.0775, 0.0794, 0.3002]), tensor([0.0662, 0.0929, 0.0834])]\n",
            "tensor(0.0662)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1c8c89da8b9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Iteration\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/chatbot/BertSum/model.py\u001b[0m in \u001b[0;36mbeam_decode\u001b[0;34m(self, src_seq, src_mask, beam_size, n_best)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 active_inst_idx_list = beam_decode_step(\n\u001b[0;32m--> 201\u001b[0;31m                     inst_dec_beams, len_dec_seq, src_seq, src_enc, inst_idx_to_position_map, beam_size)\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mactive_inst_idx_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/chatbot/BertSum/model.py\u001b[0m in \u001b[0;36mbeam_decode_step\u001b[0;34m(inst_dec_beams, len_dec_seq, src_seq, enc_output, inst_idx_to_position_map, beam_size)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mn_active_inst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst_idx_to_position_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mdec_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_beam_dec_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst_dec_beams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_dec_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mword_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_active_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/chatbot/BertSum/model.py\u001b[0m in \u001b[0;36mprepare_beam_dec_seq\u001b[0;34m(inst_dec_beams, len_dec_seq)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mprepare_beam_dec_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst_dec_beams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_dec_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 \u001b[0mdec_partial_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minst_dec_beams\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                 \u001b[0mdec_partial_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_partial_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mdec_partial_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec_partial_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_dec_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/chatbot/BertSum/model.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mprepare_beam_dec_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst_dec_beams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_dec_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 \u001b[0mdec_partial_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minst_dec_beams\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                 \u001b[0mdec_partial_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_partial_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mdec_partial_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec_partial_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_dec_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/chatbot/BertSum/transformer/Beam.py\u001b[0m in \u001b[0;36mget_current_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_current_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;34m\"Get the outputs for the current timestep.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tentative_hypothesis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_current_origin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/chatbot/BertSum/transformer/Beam.py\u001b[0m in \u001b[0;36mget_tentative_hypothesis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mhyps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hypothesis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0mhyps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mConstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBOS\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhyps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mdec_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/chatbot/BertSum/transformer/Beam.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mhyps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hypothesis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0mhyps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mConstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBOS\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhyps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mdec_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/chatbot/BertSum/transformer/Beam.py\u001b[0m in \u001b[0;36mget_hypothesis\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_ks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_ks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mhyp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_ys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_ks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tensors used as indices must be long, byte or bool tensors"
          ]
        }
      ]
    }
  ]
}